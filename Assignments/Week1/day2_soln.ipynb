{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86cfb43",
   "metadata": {},
   "source": [
    "# Complete day1 assignment using a Opensource model i.e using llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30c9ebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from scraper import fetch_website_contents\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ef224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch contents of a webpage\n",
    "url = \"https://nofluffjobs.com/artificial-intelligence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3108409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt\"\n",
    "system_prompt = \"\"\"\n",
    "You are a professional assistant that analyzes the contents of a website,\n",
    "and provides a professional, detailes summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\"\n",
    "\n",
    "# Define our user prompt\n",
    "user_prompt_prefix = \"\"\"|\n",
    "Here are the contents of a job posting website.\n",
    "If the job is related to AI, than list all those job posting with company name, role, experience expecting,work mode, salary(converting it to INR), skills required, responsibilities etc.\n",
    "Also check whether they are offering the visa and sort them based on experiece, Contenet : .\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf510277",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab16f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    web_content = fetch_website_contents(url)\n",
    "    response = ollama.chat.completions.create(\n",
    "        model=\"llama3.2:1b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt_prefix + web_content}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76fcf26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_markdown(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71254d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_markdown(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
