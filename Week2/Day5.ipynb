{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69aaea1d",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "• LLM controls the workflow\n",
    "\n",
    "• An LLM agent runs tool in loop to achieve a goal\n",
    "\n",
    "### Common features : \n",
    "\n",
    "• Memory/Persistance\n",
    "\n",
    "• Planing capabilities\n",
    "\n",
    "• Autonomy\n",
    "\n",
    "• LLM orchestration via Tools\n",
    "\n",
    "• Functionality via Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46e77cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Learning\\Udemy Course projects\\Ai Engineering core track - Ed Sonner\\LLM_Engineering_Practice\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6e34ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "openai = OpenAI()\n",
    "\n",
    "DB = \"prices.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8186e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a helpful assistant for an Airline called FlightAI.\n",
    "Give short, courteous answers, no more than 1 sentence.\n",
    "Always be accurate. If you don't know the answer, say so.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71180800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticket_price(city):\n",
    "    print(f\"DATABASE TOOL CALLED: Getting price for {city}\", flush=True)\n",
    "    with sqlite3.connect(DB) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('SELECT price FROM prices WHERE city = ?', (city.lower(),))\n",
    "        result = cursor.fetchone()\n",
    "        return f\"Ticket price to {city} is ${result[0]}\" if result else \"No price data available for this city\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595a3dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATABASE TOOL CALLED: Getting price for Paris\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ticket price to Paris is $899.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticket_price(\"Paris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95067663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'get_ticket_price',\n",
       "   'description': 'Get the price of a return ticket to the destination city.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'destination_city': {'type': 'string',\n",
       "      'description': 'The city that the customer wants to travel to'}},\n",
       "    'required': ['destination_city'],\n",
       "    'additionalProperties': False}}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "tools = [{\"type\": \"function\", \"function\": price_function}]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "474bbe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to handle if one tool need to be accessed multiple times - optimized with dictionary lookup\n",
    "def handle_tool_calls_and_return_cities(message):\n",
    "    def handle_get_price(args):\n",
    "        city = args.get('destination_city')\n",
    "        cities.append(city)\n",
    "        return get_ticket_price(city)\n",
    "\n",
    "    handlers = {\n",
    "        \"get_ticket_price\": handle_get_price,\n",
    "    }\n",
    "\n",
    "    responses = []\n",
    "    cities = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        content = handlers[tool_call.function.name](arguments)\n",
    "        responses.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": content,\n",
    "            \"tool_call_id\": tool_call.id\n",
    "        })\n",
    "    return responses, cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c329de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "    while response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        responses = handle_tool_calls(message)\n",
    "        messages.append(message)\n",
    "        messages.extend(responses)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb6c96d",
   "metadata": {},
   "source": [
    "## A bit more about what Gradio actually does:\n",
    "\n",
    "1. Gradio constructs a frontend Svelte app based on our Python description of the UI\n",
    "2. Gradio starts a server built upon the Starlette web framework listening on a free port that serves this React app\n",
    "3. Gradio creates backend routes for our callbacks, like chat(), which calls our functions\n",
    "\n",
    "And of course when Gradio generates the frontend app, it ensures that the the Submit button calls the right backend route.\n",
    "\n",
    "That's it!\n",
    "\n",
    "It's simple, and it has a result that feels magical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da67c70",
   "metadata": {},
   "source": [
    "# Let's go multi-modal!!\n",
    "\n",
    "We can use DALL-E-3, the image generation model behind GPT-4o, to make us some images\n",
    "\n",
    "Let's put this in a function called artist.\n",
    "\n",
    "### Price alert: each time I generate an image it costs about 4 cents - don't go crazy with images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ca86eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports for handling images\n",
    "\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcb760c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(city):\n",
    "    image_response = openai.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}, in a vibrant pop-art style\",\n",
    "        size=\"1024x1024\",\n",
    "        n=1,    \n",
    "        response_format=\"b64_json\",\n",
    "    )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe78f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = artist(\"Mangalore\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "850fe9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "        model=\"gpt-4o-mini-tts\",\n",
    "        voice=\"onyx\",\n",
    "        input=message\n",
    "    )\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def49af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    cities = []\n",
    "    image = None\n",
    "\n",
    "    while response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        responses, cities = handle_tool_calls_and_return_cities(message)\n",
    "        messages.append(message)\n",
    "        messages.extend(responses)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "\n",
    "    voice = talker(reply)\n",
    "\n",
    "    if cities:\n",
    "        image = artist(cities[0])\n",
    "    \n",
    "    return history, voice, image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39943c8b",
   "metadata": {},
   "source": [
    "## The 3 types of Gradio UI\n",
    "\n",
    "`gr.Interface` is for standard, simple UIs\n",
    "\n",
    "`gr.ChatInterface` is for standard ChatBot UIs\n",
    "\n",
    "`gr.Blocks` is for custom UIs where you control the components and the callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eb018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks (along with the chat() function above)\n",
    "\n",
    "def put_message_in_chatbot(message, history):\n",
    "        return \"\", history + [{\"role\":\"user\", \"content\":message}]\n",
    "\n",
    "# UI definition\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500)\n",
    "        image_output = gr.Image(height=500, interactive=False)\n",
    "    with gr.Row():\n",
    "        audio_output = gr.Audio(autoplay=True)\n",
    "    with gr.Row():\n",
    "        message = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "\n",
    "# Hooking up events to callbacks\n",
    "\n",
    "    message.submit(put_message_in_chatbot, inputs=[message, chatbot], outputs=[message, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, audio_output, image_output]\n",
    "    )\n",
    "\n",
    "ui.launch(inbrowser=True, auth=(\"user\", \"123\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4847d7f9",
   "metadata": {},
   "source": [
    "# Exercises and Business Applications\n",
    "\n",
    "Add in more tools - perhaps to simulate actually booking a flight. A student has done this and provided their example in the community contributions folder.\n",
    "\n",
    "Next: take this and apply it to your business. Make a multi-modal AI assistant with tools that could carry out an activity for your work. A customer support assistant? New employee onboarding assistant? So many possibilities! Also, see the week2 end of week Exercise in the separate Notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
